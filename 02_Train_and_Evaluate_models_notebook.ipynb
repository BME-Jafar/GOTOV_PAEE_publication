{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.listdir('/preprocessedData/sequences/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "tf.test.gpu_device_name()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "import pickle \n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# from EE_Models_v2 import Model1\n",
    "# from EE_Images import Image\n",
    "\n",
    "from tensorflow.keras.layers import LSTM, SimpleRNN, Dropout, Activation, GRU, Dense\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, TensorBoard\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras import regularizers\n",
    "from tensorflow.keras.utils import plot_model\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, concatenate\n",
    "\n",
    "from tensorflow.keras.regularizers import l2, l1\n",
    "\n",
    "from livelossplot.keras import PlotLossesCallback"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Different models functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Our proposed model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def GRUx3_Densex3(name, X_train, y_train, bmi_train, X_val, y_val, bmi_val, n_batch, n_epochs, moldel_dir, image_dir, BMI=True):\n",
    "    print('Creating functional api model')\n",
    "\n",
    "    #input1 accelerometer sensor measurements \n",
    "    input_1 = Input(shape=(X_train.shape[1], X_train.shape[2]))\n",
    "    hidden_1 = GRU(32, return_sequences=True, kernel_regularizer=l2(l=0.0001), recurrent_dropout=0.5)(input_1)\n",
    "    hidden_2 = GRU(256, return_sequences=True, kernel_regularizer=l2(l=0.0001), recurrent_dropout=0.5)(hidden_1)\n",
    "    hidden_3 = GRU(32, return_sequences=False, kernel_regularizer=l2(l=0.0001), recurrent_dropout=0.5)(hidden_2)\n",
    "    hidden_4 = Dense(32, activation='relu')(hidden_3)\n",
    "    \n",
    "    #input2 BMI of participants \n",
    "    input_2 = Input(shape=(bmi_train.shape[1],))\n",
    "    if BMI == True:\n",
    "        hidden_8 = Dense(32)(input_2)\n",
    "\n",
    "        #merge\n",
    "        con = concatenate([hidden_4, hidden_8])\n",
    "        x3 = Dense(32, activation='relu')(con)\n",
    "    else:\n",
    "        x3 = Dense(32, activation='relu')(hidden_4)\n",
    "\n",
    "    x3 = Dropout(0.2)(x3) #another change\n",
    "    x3 = Dense(16, activation='relu')(x3) #changes made\n",
    "    x3 = Dropout(0.2)(x3)\n",
    "    output = Dense(1, activation='linear')(x3)\n",
    "\n",
    "    model = Model(inputs=[input_1, input_2], outputs=output)\n",
    "    # plot_model(model, to_file=image_dir)\n",
    "\n",
    "    model.compile(loss='mean_squared_error', optimizer='adam', metrics=['mse'])\n",
    "    model.summary()\n",
    "    tbCallBack = TensorBoard(log_dir= moldel_dir + '/' + name, histogram_freq=0, write_graph=True, write_images=True)\n",
    "    # monitor = EarlyStopping(monitor='val_loss', min_delta=1e-3, patience=50, mode='auto', verbose=1)\n",
    "    checkpointer = ModelCheckpoint(filepath= moldel_dir + '/' + name + '.hdf5', \n",
    "                                  save_best_only=True, verbose=1, mode='auto', monitor='val_loss')\n",
    "    history = model.fit(x=[X_train, bmi_train], y=y_train, \n",
    "                      batch_size=n_batch, epochs=n_epochs, verbose=1, \n",
    "                      validation_data=([X_val, bmi_val], y_val), shuffle=True, \n",
    "                      callbacks=[checkpointer, tbCallBack])\n",
    "    return history"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Other models tested"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def LSTM(name, X_train, y_train, bmi_train, X_val, y_val, bmi_val, n_batch, n_epochs, moldel_dir, image_dir, BMI=True):\n",
    "    print('Creating functional api model')\n",
    "\n",
    "    #input1 accelerometer sensor measurements \n",
    "    input_1 = Input(shape=(X_train.shape[1], X_train.shape[2]))\n",
    "    hidden_1 = LSTM(32, return_sequences=True, kernel_regularizer=l2(l=0.0001), recurrent_dropout=0.5)(input_1)\n",
    "    hidden_2 = LSTM(256, return_sequences=True, kernel_regularizer=l2(l=0.0001), recurrent_dropout=0.5)(hidden_1)\n",
    "    hidden_3 = LSTM(32, return_sequences=False, kernel_regularizer=l2(l=0.0001), recurrent_dropout=0.5)(hidden_2)\n",
    "    hidden_4 = Dense(32, activation='relu')(hidden_3)\n",
    "    \n",
    "    #input2 BMI of participants \n",
    "    input_2 = Input(shape=(bmi_train.shape[1],))\n",
    "    if BMI == True:\n",
    "        hidden_8 = Dense(32)(input_2)\n",
    "\n",
    "        #merge\n",
    "        con = concatenate([hidden_4, hidden_8])\n",
    "        x3 = Dense(32, activation='relu')(con)\n",
    "    else:\n",
    "        x3 = Dense(32, activation='relu')(hidden_4)\n",
    "\n",
    "    x3 = Dropout(0.2)(x3) #another change\n",
    "    x3 = Dense(16, activation='relu')(x3) #changes made\n",
    "    x3 = Dropout(0.2)(x3)\n",
    "    output = Dense(1, activation='linear')(x3)\n",
    "\n",
    "    model = Model(inputs=[input_1, input_2], outputs=output)\n",
    "    # plot_model(model, to_file=image_dir)\n",
    "\n",
    "    model.compile(loss='mean_squared_error', optimizer='adam', metrics=['mse'])\n",
    "    model.summary()\n",
    "    tbCallBack = TensorBoard(log_dir= moldel_dir + '/' + name, histogram_freq=0, write_graph=True, write_images=True)\n",
    "    # monitor = EarlyStopping(monitor='val_loss', min_delta=1e-3, patience=50, mode='auto', verbose=1)\n",
    "    checkpointer = ModelCheckpoint(filepath= moldel_dir + '/' + name + '.hdf5', \n",
    "                                  save_best_only=True, verbose=1, mode='auto', monitor='val_loss')\n",
    "    history = model.fit(x=[X_train, bmi_train], y=y_train, \n",
    "                      batch_size=n_batch, epochs=n_epochs, verbose=1, \n",
    "                      validation_data=([X_val, bmi_val], y_val), shuffle=True, \n",
    "                      callbacks=[checkpointer, tbCallBack])\n",
    "    return history\n",
    "\n",
    "def simpleRNN(name, X_train, y_train, bmi_train, X_val, y_val, bmi_val, n_batch, n_epochs, moldel_dir, image_dir, BMI=True):\n",
    "    print('Creating functional api model')\n",
    "\n",
    "    #input1 accelerometer sensor measurements \n",
    "    input_1 = Input(shape=(X_train.shape[1], X_train.shape[2]))\n",
    "    hidden_1 = SimpleRNN(32, return_sequences=True, kernel_regularizer=l2(l=0.0001), recurrent_dropout=0.5)(input_1)\n",
    "    hidden_2 = SimpleRNN(256, return_sequences=True, kernel_regularizer=l2(l=0.0001), recurrent_dropout=0.5)(hidden_1)\n",
    "    hidden_3 = SimpleRNN(32, return_sequences=False, kernel_regularizer=l2(l=0.0001), recurrent_dropout=0.5)(hidden_2)\n",
    "    hidden_4 = Dense(32, activation='relu')(hidden_3)\n",
    "    \n",
    "    #input2 BMI of participants \n",
    "    input_2 = Input(shape=(bmi_train.shape[1],))\n",
    "    if BMI == True:\n",
    "        hidden_8 = Dense(32)(input_2)\n",
    "\n",
    "        #merge\n",
    "        con = concatenate([hidden_4, hidden_8])\n",
    "        x3 = Dense(32, activation='relu')(con)\n",
    "    else:\n",
    "        x3 = Dense(32, activation='relu')(hidden_4)\n",
    "\n",
    "    x3 = Dropout(0.2)(x3) #another change\n",
    "    x3 = Dense(16, activation='relu')(x3) #changes made\n",
    "    x3 = Dropout(0.2)(x3)\n",
    "    output = Dense(1, activation='linear')(x3)\n",
    "\n",
    "    model = Model(inputs=[input_1, input_2], outputs=output)\n",
    "    # plot_model(model, to_file=image_dir)\n",
    "\n",
    "    model.compile(loss='mean_squared_error', optimizer='adam', metrics=['mse'])\n",
    "    model.summary()\n",
    "    tbCallBack = TensorBoard(log_dir= moldel_dir + '/' + name, histogram_freq=0, write_graph=True, write_images=True)\n",
    "    # monitor = EarlyStopping(monitor='val_loss', min_delta=1e-3, patience=50, mode='auto', verbose=1)\n",
    "    checkpointer = ModelCheckpoint(filepath= moldel_dir + '/' + name + '.hdf5', \n",
    "                                  save_best_only=True, verbose=1, mode='auto', monitor='val_loss')\n",
    "    history = model.fit(x=[X_train, bmi_train], y=y_train, \n",
    "                      batch_size=n_batch, epochs=n_epochs, verbose=1, \n",
    "                      validation_data=([X_val, bmi_val], y_val), shuffle=True, \n",
    "                      callbacks=[checkpointer, tbCallBack])\n",
    "    return history\n",
    "\n",
    "def GRUx5_Densex3(name, X_train, y_train, bmi_train, X_val, y_val, bmi_val, n_batch, n_epochs, moldel_dir, image_dir, BMI=True):\n",
    "    print('Creating functional api model')\n",
    "\n",
    "    #input1 accelerometer sensor measurements \n",
    "    input_1 = Input(shape=(X_train.shape[1], X_train.shape[2]))\n",
    "    hidden_1 = GRU(32, return_sequences=True, kernel_regularizer=l2(l=0.0001), recurrent_dropout=0.5)(input_1)\n",
    "    hidden_2_1 = GRU(32, return_sequences=True, kernel_regularizer=l2(l=0.0001), recurrent_dropout=0.5)(hidden_1)\n",
    "    hidden_2_2 = GRU(256, return_sequences=True, kernel_regularizer=l2(l=0.0001), recurrent_dropout=0.5)(hidden_2_1)\n",
    "    hidden_2_3 = GRU(32, return_sequences=True, kernel_regularizer=l2(l=0.0001), recurrent_dropout=0.5)(hidden_2_2)\n",
    "    hidden_3 = GRU(32, return_sequences=False, kernel_regularizer=l2(l=0.0001), recurrent_dropout=0.5)(hidden_2_3)\n",
    "    hidden_4 = Dense(32, activation='relu')(hidden_3)  \n",
    "    \n",
    "    #input2 BMI of participants \n",
    "    input_2 = Input(shape=(bmi_train.shape[1],))\n",
    "    if BMI == True:\n",
    "        hidden_8 = Dense(32)(input_2)\n",
    "\n",
    "        #merge\n",
    "        con = concatenate([hidden_4, hidden_8])\n",
    "        x3 = Dense(32, activation='relu')(con)\n",
    "    else:\n",
    "        x3 = Dense(32, activation='relu')(hidden_4)\n",
    "\n",
    "    x3 = Dropout(0.2)(x3) #another change\n",
    "    x3 = Dense(16, activation='relu')(x3) #changes made\n",
    "    x3 = Dropout(0.2)(x3)\n",
    "    output = Dense(1, activation='linear')(x3)\n",
    "\n",
    "    model = Model(inputs=[input_1, input_2], outputs=output)\n",
    "    # plot_model(model, to_file=image_dir)\n",
    "\n",
    "    model.compile(loss='mean_squared_error', optimizer='adam', metrics=['mse'])\n",
    "    model.summary()\n",
    "    tbCallBack = TensorBoard(log_dir= moldel_dir + '/' + name, histogram_freq=0, write_graph=True, write_images=True)\n",
    "    # monitor = EarlyStopping(monitor='val_loss', min_delta=1e-3, patience=50, mode='auto', verbose=1)\n",
    "    checkpointer = ModelCheckpoint(filepath= moldel_dir + '/' + name + '.hdf5', \n",
    "                                  save_best_only=True, verbose=1, mode='auto', monitor='val_loss')\n",
    "    history = model.fit(x=[X_train, bmi_train], y=y_train, \n",
    "                      batch_size=n_batch, epochs=n_epochs, verbose=1, \n",
    "                      validation_data=([X_val, bmi_val], y_val), shuffle=True, \n",
    "                      callbacks=[checkpointer, tbCallBack])\n",
    "    return history\n",
    "\n",
    "def GRUx4_Densex2(name, X_train, y_train, bmi_train, X_val, y_val, bmi_val, n_batch, n_epochs, moldel_dir, image_dir, BMI=True):\n",
    "    print('Creating functional api model')\n",
    "\n",
    "    #input1 accelerometer sensor measurements \n",
    "    input_1 = Input(shape=(X_train.shape[1], X_train.shape[2]))\n",
    "    hidden_1 = GRU(32, return_sequences=True, kernel_regularizer=l2(l=0.0001), recurrent_dropout=0.5)(input_1)\n",
    "    hidden_2_1 = GRU(32, return_sequences=True, kernel_regularizer=l2(l=0.0001), recurrent_dropout=0.5)(hidden_1)\n",
    "    hidden_2_2 = GRU(256, return_sequences=True, kernel_regularizer=l2(l=0.0001), recurrent_dropout=0.5)(hidden_2_1)\n",
    "    hidden_3 = GRU(32, return_sequences=False, kernel_regularizer=l2(l=0.0001), recurrent_dropout=0.5)(hidden_2_2)\n",
    "    hidden_4 = Dense(32, activation='relu')(hidden_3)  \n",
    "    \n",
    "    #input2 BMI of participants \n",
    "    input_2 = Input(shape=(bmi_train.shape[1],))\n",
    "    if BMI == True:\n",
    "        hidden_8 = Dense(32)(input_2)\n",
    "\n",
    "        #merge\n",
    "        con = concatenate([hidden_4, hidden_8])\n",
    "        x3 = Dense(32, activation='relu')(con)\n",
    "    else:\n",
    "        x3 = Dense(32, activation='relu')(hidden_4)\n",
    "\n",
    "    x3 = Dropout(0.2)(x3) #another change\n",
    "    x3 = Dense(16, activation='relu')(x3) #changes made\n",
    "    x3 = Dropout(0.2)(x3)\n",
    "    output = Dense(1, activation='linear')(x3)\n",
    "\n",
    "    model = Model(inputs=[input_1, input_2], outputs=output)\n",
    "    # plot_model(model, to_file=image_dir)\n",
    "\n",
    "    model.compile(loss='mean_squared_error', optimizer='adam', metrics=['mse'])\n",
    "    model.summary()\n",
    "    tbCallBack = TensorBoard(log_dir= moldel_dir + '/' + name, histogram_freq=0, write_graph=True, write_images=True)\n",
    "    # monitor = EarlyStopping(monitor='val_loss', min_delta=1e-3, patience=50, mode='auto', verbose=1)\n",
    "    checkpointer = ModelCheckpoint(filepath= moldel_dir + '/' + name + '.hdf5', \n",
    "                                  save_best_only=True, verbose=1, mode='auto', monitor='val_loss')\n",
    "    history = model.fit(x=[X_train, bmi_train], y=y_train, \n",
    "                      batch_size=n_batch, epochs=n_epochs, verbose=1, \n",
    "                      validation_data=([X_val, bmi_val], y_val), shuffle=True, \n",
    "                      callbacks=[checkpointer, tbCallBack])\n",
    "    return history\n",
    "\n",
    "def GRUx3_Densex2(name, X_train, y_train, bmi_train, X_val, y_val, bmi_val, n_batch, n_epochs, moldel_dir, image_dir, BMI=True):\n",
    "    print('Creating functional api model')\n",
    "\n",
    "    #input1 accelerometer sensor measurements \n",
    "    input_1 = Input(shape=(X_train.shape[1], X_train.shape[2]))\n",
    "    gru1 = GRU(32, return_sequences=True, kernel_regularizer=l2(l=0.0001), recurrent_dropout=0.5)(input_1)\n",
    "    gru2 = GRU(256, return_sequences=True, kernel_regularizer=l2(l=0.0001), recurrent_dropout=0.5)(gru1)\n",
    "    gru3 = GRU(32, return_sequences=False, kernel_regularizer=l2(l=0.0001), recurrent_dropout=0.5)(gru2)\n",
    "    den1 = Dense(32, activation='relu')(gru3)\n",
    "    \n",
    "    #input2 BMI of participants \n",
    "    input_2 = Input(shape=(bmi_train.shape[1],))\n",
    "    if BMI == True:\n",
    "        bmi_layer = Dense(32)(input_2)\n",
    "\n",
    "        #merge\n",
    "        con = concatenate([den1, bmi_layer])\n",
    "        den2 = Dense(32, activation='relu')(con)\n",
    "    else:\n",
    "        den2 = Dense(32, activation='relu')(den1)\n",
    "\n",
    "    drop1 = Dropout(0.2)(den2) #another change\n",
    "#     den3 = Dense(16, activation='relu')(drop1) #changes made\n",
    "#     drop2 = Dropout(0.2)(den3)\n",
    "    output = Dense(1, activation='linear')(drop1)\n",
    "\n",
    "    model = Model(inputs=[input_1, input_2], outputs=output)\n",
    "\n",
    "# plot_model(model, to_file=image_dir)\n",
    "\n",
    "    model.compile(loss='mean_squared_error', optimizer='adam', metrics=['mse'])\n",
    "    model.summary()\n",
    "    tbCallBack = TensorBoard(log_dir= moldel_dir + '/' + name, histogram_freq=0, write_graph=True, write_images=True)\n",
    "    # monitor = EarlyStopping(monitor='val_loss', min_delta=1e-3, patience=50, mode='auto', verbose=1)\n",
    "    checkpointer = ModelCheckpoint(filepath= moldel_dir + '/' + name + '.hdf5', \n",
    "                                  save_best_only=True, verbose=1, mode='auto', monitor='val_loss')\n",
    "    history = model.fit(x=[X_train, bmi_train], y=y_train, \n",
    "                      batch_size=n_batch, epochs=n_epochs, verbose=1, \n",
    "                      validation_data=([X_val, bmi_val], y_val), shuffle=True, \n",
    "                      callbacks=[checkpointer, tbCallBack])\n",
    "    return history\n",
    "\n",
    "\n",
    "def GRUx2_Densex3(name, X_train, y_train, bmi_train, X_val, y_val, bmi_val, n_batch, n_epochs, moldel_dir, image_dir, BMI=True):\n",
    "    print('Creating functional api model')\n",
    "\n",
    "    #input1 accelerometer sensor measurements \n",
    "    input_1 = Input(shape=(X_train.shape[1], X_train.shape[2]))\n",
    "    gru1 = GRU(32, return_sequences=True, kernel_regularizer=l2(l=0.0001), recurrent_dropout=0.5)(input_1)\n",
    "    gru2 = GRU(256, return_sequences=False, kernel_regularizer=l2(l=0.0001), recurrent_dropout=0.5)(gru1)\n",
    "#     gru3 = GRU(32, return_sequences=False, kernel_regularizer=l2(l=0.0001), recurrent_dropout=0.5)(gru1)\n",
    "    den1 = Dense(32, activation='relu')(gru2)\n",
    "    \n",
    "    #input2 BMI of participants \n",
    "    input_2 = Input(shape=(bmi_train.shape[1],))\n",
    "    if BMI == True:\n",
    "        bmi_layer = Dense(32)(input_2)\n",
    "\n",
    "        #merge\n",
    "        con = concatenate([den1, bmi_layer])\n",
    "        den2 = Dense(32, activation='relu')(con)\n",
    "    else:\n",
    "        den2 = Dense(32, activation='relu')(den1)\n",
    "\n",
    "    drop1 = Dropout(0.2)(den2) #another change\n",
    "    den3 = Dense(16, activation='relu')(drop1) #changes made\n",
    "    drop2 = Dropout(0.2)(den3)\n",
    "    output = Dense(1, activation='linear')(den3)\n",
    "\n",
    "    model = Model(inputs=[input_1, input_2], outputs=output)\n",
    "\n",
    "# plot_model(model, to_file=image_dir)\n",
    "\n",
    "    model.compile(loss='mean_squared_error', optimizer='adam', metrics=['mse'])\n",
    "    model.summary()\n",
    "    tbCallBack = TensorBoard(log_dir= moldel_dir + '/' + name, histogram_freq=0, write_graph=True, write_images=True)\n",
    "    # monitor = EarlyStopping(monitor='val_loss', min_delta=1e-3, patience=50, mode='auto', verbose=1)\n",
    "    checkpointer = ModelCheckpoint(filepath= moldel_dir + '/' + name + '.hdf5', \n",
    "                                  save_best_only=True, verbose=1, mode='auto', monitor='val_loss')\n",
    "    history = model.fit(x=[X_train, bmi_train], y=y_train, \n",
    "                      batch_size=n_batch, epochs=n_epochs, verbose=1, \n",
    "                      validation_data=([X_val, bmi_val], y_val), shuffle=True, \n",
    "                      callbacks=[checkpointer, tbCallBack])\n",
    "    return history\n",
    "\n",
    "def GRUx2_Densex2(name, X_train, y_train, bmi_train, X_val, y_val, bmi_val, n_batch, n_epochs, moldel_dir, image_dir, BMI=True):\n",
    "    print('Creating functional api model')\n",
    "\n",
    "    #input1 accelerometer sensor measurements \n",
    "    input_1 = Input(shape=(X_train.shape[1], X_train.shape[2]))\n",
    "    gru1 = GRU(32, return_sequences=True, kernel_regularizer=l2(l=0.0001), recurrent_dropout=0.5)(input_1)\n",
    "    gru2 = GRU(256, return_sequences=False, kernel_regularizer=l2(l=0.0001), recurrent_dropout=0.5)(gru1)\n",
    "#     gru3 = GRU(32, return_sequences=False, kernel_regularizer=l2(l=0.0001), recurrent_dropout=0.5)(gru2)\n",
    "    den1 = Dense(32, activation='relu')(gru2)\n",
    "    \n",
    "    #input2 BMI of participants \n",
    "    input_2 = Input(shape=(bmi_train.shape[1],))\n",
    "    if BMI == True:\n",
    "        bmi_layer = Dense(32)(input_2)\n",
    "\n",
    "        #merge\n",
    "        con = concatenate([den1, bmi_layer])\n",
    "        den2 = Dense(32, activation='relu')(con)\n",
    "    else:\n",
    "        den2 = Dense(32, activation='relu')(den1)\n",
    "\n",
    "    drop1 = Dropout(0.2)(den2) #another change\n",
    "#     den3 = Dense(16, activation='relu')(drop1) #changes made\n",
    "#     drop2 = Dropout(0.2)(den3)\n",
    "    output = Dense(1, activation='linear')(drop1)\n",
    "\n",
    "    model = Model(inputs=[input_1, input_2], outputs=output)\n",
    "\n",
    "# plot_model(model, to_file=image_dir)\n",
    "\n",
    "    model.compile(loss='mean_squared_error', optimizer='adam', metrics=['mse'])\n",
    "    model.summary()\n",
    "    tbCallBack = TensorBoard(log_dir= moldel_dir + '/' + name, histogram_freq=0, write_graph=True, write_images=True)\n",
    "    # monitor = EarlyStopping(monitor='val_loss', min_delta=1e-3, patience=50, mode='auto', verbose=1)\n",
    "    checkpointer = ModelCheckpoint(filepath= moldel_dir + '/' + name + '.hdf5', \n",
    "                                  save_best_only=True, verbose=1, mode='auto', monitor='val_loss')\n",
    "    history = model.fit(x=[X_train, bmi_train], y=y_train, \n",
    "                      batch_size=n_batch, epochs=n_epochs, verbose=1, \n",
    "                      validation_data=([X_val, bmi_val], y_val), shuffle=True, \n",
    "                      callbacks=[checkpointer, tbCallBack])\n",
    "    return history\n",
    "\n",
    "def GRUx1_Densex2(name, X_train, y_train, bmi_train, X_val, y_val, bmi_val, n_batch, n_epochs, moldel_dir, image_dir, BMI=True):\n",
    "    print('Creating functional api model')\n",
    "\n",
    "    #input1 accelerometer sensor measurements \n",
    "    input_1 = Input(shape=(X_train.shape[1], X_train.shape[2]))\n",
    "#     gru1 = GRU(32, return_sequences=True, kernel_regularizer=l2(l=0.0001), recurrent_dropout=0.5)(input_1)\n",
    "#     gru2 = GRU(256, return_sequences=True, kernel_regularizer=l2(l=0.0001), recurrent_dropout=0.5)(gru1)\n",
    "    gru3 = GRU(32, return_sequences=False, kernel_regularizer=l2(l=0.0001), recurrent_dropout=0.5)(input_1)\n",
    "    den1 = Dense(32, activation='relu')(gru3)\n",
    "    \n",
    "    #input2 BMI of participants \n",
    "    input_2 = Input(shape=(bmi_train.shape[1],))\n",
    "    if BMI == True:\n",
    "        bmi_layer = Dense(32)(input_2)\n",
    "\n",
    "        #merge\n",
    "        con = concatenate([den1, bmi_layer])\n",
    "        den2 = Dense(32, activation='relu')(con)\n",
    "    else:\n",
    "        den2 = Dense(32, activation='relu')(den1)\n",
    "\n",
    "    drop1 = Dropout(0.2)(den2) #another change\n",
    "#     den3 = Dense(16, activation='relu')(drop1) #changes made\n",
    "#     drop2 = Dropout(0.2)(den3)\n",
    "    output = Dense(1, activation='linear')(drop1)\n",
    "\n",
    "    model = Model(inputs=[input_1, input_2], outputs=output)\n",
    "\n",
    "# plot_model(model, to_file=image_dir)\n",
    "\n",
    "    model.compile(loss='mean_squared_error', optimizer='adam', metrics=['mse'])\n",
    "    model.summary()\n",
    "    tbCallBack = TensorBoard(log_dir= moldel_dir + '/' + name, histogram_freq=0, write_graph=True, write_images=True)\n",
    "    # monitor = EarlyStopping(monitor='val_loss', min_delta=1e-3, patience=50, mode='auto', verbose=1)\n",
    "    checkpointer = ModelCheckpoint(filepath= moldel_dir + '/' + name + '.hdf5', \n",
    "                                  save_best_only=True, verbose=1, mode='auto', monitor='val_loss')\n",
    "    history = model.fit(x=[X_train, bmi_train], y=y_train, \n",
    "                      batch_size=n_batch, epochs=n_epochs, verbose=1, \n",
    "                      validation_data=([X_val, bmi_val], y_val), shuffle=True, \n",
    "                      callbacks=[checkpointer, tbCallBack])\n",
    "    return history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train models function\n",
    "def train_model(list_of_participants, orig_seq_path, seq_path, device, EE_modeling, image_dir, model_dir, predPlot_dir, BMI):\n",
    "######\n",
    "# Train a given model using LOSO-CV given the training sequences. If you want to train with predicted activities, \n",
    "# use as input the sequences with predicted activity labels included.\n",
    "    # list_of_participants: the list of participants to perform LOSO (all 28 that have COSMED data)\n",
    "    # orig_seq_path: sequences directory with original EEm (for validation set)\n",
    "    # seq_path: sequences directory with downsampled (10seconds) EEm (for train set)\n",
    "    # device: which accelerometers to use\n",
    "        # - 'aw': for both ankle and wrist data\n",
    "        # - 'ankle': for only ankle data\n",
    "        # - 'wrist': for only wrist data\n",
    "    # EE_modeling: model function\n",
    "    # image_dir: directory to save train images\n",
    "    # model_dir: directory to save trained LOSO-CV models\n",
    "    # predPlot_dir: directory to save trueVSpredicted plots    \n",
    "    # BMI: 'True' or 'False'. True in order to train with participant level data (age, sex, weight, height, BMI),\n",
    "    #                         False in order to train model without them\n",
    "######        \n",
    "    #initialize\n",
    "    if not os.path.exists(model_dir):\n",
    "        os.makedirs(model_dir) \n",
    "    if not os.path.exists(image_dir):\n",
    "        os.makedirs(image_dir)\n",
    "        os.makedirs(predPlot_dir)\n",
    "    # run over all models\n",
    "    for i in list_of_participants:\n",
    "        if i in [2,3,4,19]: \n",
    "            continue\n",
    "        else:\n",
    "            if len(str(i)) ==1:\n",
    "                name = 'GOTOV0'+str(i)\n",
    "            else:\n",
    "                name = 'GOTOV'+str(i)\n",
    "            #fi\n",
    "        #fi\n",
    "        if os.path.exists(seq_path+name+'.pkl') == True:\n",
    "            part =  model_name+'_'+ name\n",
    "            print('Load sequences of participant', name)\n",
    "            with open(seq_path+name+'.pkl','rb') as f:\n",
    "                X_train, y_train, ytrain_time, bmi_train, X_val, y_val, yval_time, bmi_val, X_test, y_test, ytest_time, bmi_test, scaler = pickle.load(f)\n",
    "            \n",
    "            # load the orignal val and test\n",
    "            with open(orig_seq_path+name+'.pkl','rb') as f:\n",
    "                X_train1, y_train1, ytrain_time1, bmi_train1, X_val, y_val, yval_time, bmi_val, X_test, y_test, ytest_time, bmi_test, scaler = pickle.load(f)\n",
    "\n",
    "            X_train1, y_train1, ytrain_time1 = [],[],[]\n",
    "\n",
    "            # keep only one device data\n",
    "            if device == 'ankle':\n",
    "                X_train = X_train[:,:,0:3]\n",
    "                X_val = X_val[:,:,0:3]\n",
    "                X_test = X_test[:,:,0:3]\n",
    "            elif device == 'wrist':\n",
    "                X_train = X_train[:,:,3:6]\n",
    "                X_val = X_val[:,:,3:6]\n",
    "                X_test = X_test[:,:,3:6]\n",
    "\n",
    "            print('Training model... ')\n",
    "            model = EE_modeling(name, X_train, y_train, bmi_train, X_val, y_val, bmi_val, n_batch, epochs, model_dir, image_dir, BMI)\n",
    "\n",
    "            plt.plot(model.history['mse'])\n",
    "            plt.plot(model.history['val_mse'])\n",
    "            plt.title('model Mean Square Error')\n",
    "            plt.ylabel('Mean Square Error')\n",
    "            plt.xlabel('epoch')\n",
    "            plt.legend(['train', 'val'], loc='upper left')\n",
    "            plt.savefig(image_dir + name + '_mse.pdf')\n",
    "            plt.show()\n",
    "            # summarize history for loss\n",
    "            plt.plot(model.history['loss'])\n",
    "            plt.plot(model.history['val_loss'])\n",
    "            plt.title('model loss')\n",
    "            plt.ylabel('loss')\n",
    "            plt.xlabel('epoch')\n",
    "            plt.legend(['train', 'val'], loc='upper left')\n",
    "            plt.savefig(image_dir + name + '_loss.pdf')\n",
    "            plt.show()\n",
    "        else:\n",
    "            print('filepath doesnt exist')        \n",
    "        #fi\n",
    "    #efor\n",
    "#eDef"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#predict function\n",
    "def predict_EE(list_of_models, trained_models_dir, target_seqs_dir, EEm_details, results_dir, device):\n",
    "######\n",
    "# Predict EEm and evaluate the LOSO-CV models.\n",
    "    # list_of_models: the list of trained LOSO_CV models(all 28 probably)\n",
    "    # trained_models_dir: trained models directory\n",
    "    # target_seqs_dir: test sequences directory\n",
    "    # results_dir: directory to save resulted figures and CSVs\n",
    "    # device: which accelerometers to use\n",
    "        # - 'aw': for both ankle and wrist data\n",
    "        # - 'ankle': for only ankle data\n",
    "        # - 'wrist': for only wrist data    \n",
    "######          \n",
    "    #initialize\n",
    "    get_all_patients_errors = pd.DataFrame(columns=['participant', 'rsquared', 'inRsquared', 'outRsquared', 'rms', 'inRms', 'outRms'])\n",
    "    stats_EEm_results = pd.DataFrame(columns=['participant', \n",
    "                                              'true_tot_mean', 'true_in_mean', 'true_out_mean', \n",
    "                                              'pred_tot_mean', 'pred_in_mean', 'pred_out_mean'])\n",
    "\n",
    "    df_allPred = pd.DataFrame()\n",
    "    df_allPredin = pd.DataFrame()\n",
    "    df_allPredout = pd.DataFrame()\n",
    "    \n",
    "    # run over all models\n",
    "    for i in list_of_models:\n",
    "        if i in [2,3,4,19]: \n",
    "            continue\n",
    "        else:\n",
    "            if len(str(i)) ==1: \n",
    "                name = 'GOTOV0'+str(i)\n",
    "            else:\n",
    "                name = 'GOTOV'+str(i)\n",
    "            #fi\n",
    "        #fi\n",
    "\n",
    "        # import from file the time to split indoors to outdoors data\n",
    "        time = EEm_details['timeToSplit'][EEm_details['participant']==name].values[0]    \n",
    "        if os.path.exists(trained_models_dir + name +'.hdf5') == True: \n",
    "            print('Predicting test for patient', name)\n",
    "            with open(target_seqs_dir+name+'.pkl','rb') as f:\n",
    "                X_train, y_train, ytrain_time, bmi_train,X_val, y_val, yval_time, bmi_val, X_test, y_test, ytest_time, bmi_test, scaler = pickle.load(f)\n",
    "\n",
    "            # keep only one device data\n",
    "            if device == 'ankle':\n",
    "                X_train = X_train[:,:,0:3]\n",
    "                X_val = X_val[:,:,0:3]\n",
    "                X_test1 = X_test[:,:,0:3]\n",
    "            elif device == 'wrist':\n",
    "                X_train = X_train[:,:,3:6]\n",
    "                X_val = X_val[:,:,3:6]\n",
    "                X_test1 = X_test[:,:,3:6]\n",
    "            else:\n",
    "                X_test1 = X_test\n",
    "            #fi\n",
    "            print('loading model....')\n",
    "            model = load_model(trained_models_dir+name+ '.hdf5')\n",
    "            print('predicting....')\n",
    "            yhat = model.predict([X_test1, bmi_test])\n",
    "            \n",
    "            X_test = X_test.reshape(-1, X_test.shape[2])\n",
    "            \n",
    "            print('inverting...')\n",
    "            inv_yhat = np.empty((X_test.shape[0], 1))\n",
    "            inv_yhat.fill(np.nan)\n",
    "            inv_yhat[:yhat.shape[0]] = yhat\n",
    "\n",
    "            inv_yhat = np.concatenate((X_test, inv_yhat), axis=1)\n",
    "            inv_yhat = np.ma.array(inv_yhat, mask=np.isnan(inv_yhat))\n",
    "            inv_yhat = scaler.inverse_transform(inv_yhat)\n",
    "            inv_yhat = inv_yhat[:, 6]\n",
    "\n",
    "            y_test = y_test.reshape(len(y_test), 1)\n",
    "            inv_ytest = np.empty((X_test.shape[0], 1))\n",
    "            inv_ytest.fill(np.nan)\n",
    "            inv_ytest[:y_test.shape[0]] = y_test\n",
    "\n",
    "            inv_ytest = np.concatenate((X_test, inv_ytest), axis=1)\n",
    "            inv_ytest = np.ma.array(inv_ytest, mask=np.isnan(inv_ytest))\n",
    "            inv_ytest = scaler.inverse_transform(inv_ytest)\n",
    "            inv_ytest = inv_ytest[:, 6]\n",
    "\n",
    "            inv_yhat = inv_yhat[~np.isnan(inv_yhat)]\n",
    "            inv_ytest = inv_ytest[~np.isnan(inv_ytest)]\n",
    "\n",
    "            df_test = pd.DataFrame(data=inv_ytest, index=ytest_time, columns=['True'])\n",
    "            df_test['Predicted'] = inv_yhat\n",
    "\n",
    "            df_test['participant'] = name        \n",
    "            df_allPred = df_allPred.append(df_test)\n",
    "            \n",
    "            # calculate errors\n",
    "            rsquared = r2_score(df_test['True'], df_test['Predicted'])\n",
    "            print('rsquared...', rsquared)\n",
    "            rms = sqrt(mean_squared_error(df_test['True'], df_test['Predicted']))\n",
    "            print('rms...', rms)\n",
    "\n",
    "            print('Create result CSVs and figures ...')\n",
    "            true_tot_mean = np.mean(df_test['True'])\n",
    "            pred_tot_mean = np.mean(df_test['Predicted'])        \n",
    "            true_tot_std  = np.std(df_test['True'])\n",
    "            pred_tot_std  = np.std(df_test['Predicted'])        \n",
    "\n",
    "            z = np.polyfit(df_test['True'], df_test['Predicted'], 1)\n",
    "            p = np.poly1d(z)\n",
    "            x_max = int(np.max(df_test['True'])+2)\n",
    "            y_max = int(np.max(df_test['Predicted'])+2)\n",
    "\n",
    "            plt.figure(figsize=(15,8))\n",
    "            plt.plot(df_test['True'], label='True_EE')\n",
    "            plt.plot(df_test['Predicted'], label='Predicted_EE')\n",
    "            plt.legend(loc='upper left')\n",
    "            plt.title(name)\n",
    "            plt.savefig(results_dir+name+'.pdf')\n",
    "            # plt.show()\n",
    "            plt.close()\n",
    "\n",
    "            if np.isnan(EEm_details['outEEm'][EEm_details['participant']==name].values) == False:\n",
    "                # indoors\n",
    "                indoors = df_test[df_test.index <= time]#'2016-02-19 11:12:25.004000']\n",
    "                indoors['participant'] = name        \n",
    "                df_allPredin = df_allPredin.append(indoors)\n",
    "\n",
    "                in_rsquared = r2_score(indoors['True'], indoors['Predicted'])\n",
    "                in_rms = sqrt(mean_squared_error(indoors['True'], indoors['Predicted']))\n",
    "                print('in :', in_rsquared)\n",
    "                true_in_mean = np.mean(indoors['True'])\n",
    "                pred_in_mean = np.mean(indoors['Predicted'])\n",
    "                true_in_std  = np.std(indoors['True'])\n",
    "                pred_in_std  = np.std(indoors['Predicted'])        \n",
    "\n",
    "                # plot\n",
    "                plt.figure(figsize=(15,8))\n",
    "                plt.plot(indoors['True'], label='True_EE')\n",
    "                plt.plot(indoors['Predicted'], label='Predicted_EE')\n",
    "                plt.title(name)\n",
    "                plt.legend(loc='upper left')\n",
    "                plt.savefig(results_dir+name+'_in.pdf')\n",
    "    #             plt.show()\n",
    "                plt.close()\n",
    "\n",
    "                # outdoors\n",
    "                outdoors = df_test[df_test.index > time]#'2016-02-19 11:12:25.004000']\n",
    "                outdoors['participant'] = name        \n",
    "                df_allPredout = df_allPredout.append(outdoors)\n",
    "\n",
    "                out_rsquared = r2_score(outdoors['True'], outdoors['Predicted'])\n",
    "                out_rms = sqrt(mean_squared_error(outdoors['True'], outdoors['Predicted']))            \n",
    "                print('out:', out_rsquared)\n",
    "                true_out_mean = np.mean(outdoors['True'])\n",
    "                pred_out_mean = np.mean(outdoors['Predicted'])            \n",
    "                true_out_std  = np.std(outdoors['True'])\n",
    "                pred_out_std  = np.std(outdoors['Predicted'])        \n",
    "\n",
    "                # plot\n",
    "                plt.figure(figsize=(15,8))\n",
    "                plt.title(name)\n",
    "                plt.plot(outdoors['True'], label='True_EE')\n",
    "                plt.plot(outdoors['Predicted'], label='Predicted_EE')\n",
    "                plt.legend(loc='upper left')\n",
    "                plt.savefig(results_dir+name+'_out.pdf')\n",
    "    #             plt.show()\n",
    "                plt.close()\n",
    "\n",
    "                # scatter plot\n",
    "                plt.figure(figsize=(15,8))\n",
    "                plt.xlim([-1,x_max])\n",
    "                plt.ylim([-1,y_max])            \n",
    "                plt.scatter(indoors['True'], indoors['Predicted'], c ='green', alpha=0.5, label='Indoors')\n",
    "                plt.scatter(outdoors['True'], outdoors['Predicted'], c ='orange', alpha=0.5, label='Outdoors')\n",
    "                plt.plot(df_test['True'],p(df_test['True']),\"b\")\n",
    "                plt.legend(loc='upper right')\n",
    "                plt.title(name)\n",
    "                plt.xlabel('True')\n",
    "                plt.ylabel('Predicted')\n",
    "                plt.savefig(results_dir+name+'_scatter.pdf')            \n",
    "    #             plt.show()\n",
    "                plt.close()\n",
    "\n",
    "            else:\n",
    "                in_rsquared   = None\n",
    "                in_rms        = None\n",
    "                out_rsquared  = None\n",
    "                out_rms       = None\n",
    "                true_in_mean  = None\n",
    "                true_out_mean = None\n",
    "                true_in_std   = None\n",
    "                true_out_std  = None\n",
    "                pred_in_mean  = None\n",
    "                pred_out_mean = None\n",
    "                pred_in_std   = None\n",
    "                pred_out_std  = None\n",
    "\n",
    "                # scatter plot\n",
    "                plt.figure(figsize=(15,8))\n",
    "                plt.xlim([-1,x_max])\n",
    "                plt.ylim([-1,y_max])\n",
    "                plt.scatter(df_test['True'], df_test['Predicted'], c ='green', alpha=0.5, label='Indoors')\n",
    "                plt.plot(df_test['True'],p(df_test['True']),\"b\")            \n",
    "                plt.legend(loc='upper right')\n",
    "                plt.title(name)\n",
    "                plt.xlabel('True')\n",
    "                plt.ylabel('Predicted')\n",
    "                plt.savefig(results_dir+name+'_scatter.pdf')\n",
    "    #             plt.show()\n",
    "                plt.close()\n",
    "\n",
    "                df_allPredin = df_allPredin.append(df_test)\n",
    "            #fi\n",
    "\n",
    "            # report results\n",
    "            get_all_patients_errors = get_all_patients_errors.append({'participant': name,\n",
    "                                                                      'rsquared'   : rsquared,\n",
    "                                                                      'inRsquared' : in_rsquared,\n",
    "                                                                      'outRsquared': out_rsquared,\n",
    "                                                                      'rms'        : rms,\n",
    "                                                                      'inRms'      : in_rms,\n",
    "                                                                      'outRms'     : out_rms},\n",
    "                                                                     ignore_index=True) \n",
    "\n",
    "            stats_EEm_results = stats_EEm_results.append({'participant'  : name,\n",
    "                                                          'true_tot_mean': true_tot_mean,\n",
    "                                                          'true_in_mean' : true_in_mean,\n",
    "                                                          'true_out_mean': true_out_mean,\n",
    "                                                          'true_tot_std' : true_tot_std,\n",
    "                                                          'true_in_std'  : true_in_std,\n",
    "                                                          'true_out_std' : true_out_std,\n",
    "                                                          'pred_tot_mean': pred_tot_mean,\n",
    "                                                          'pred_in_mean' : pred_in_mean,\n",
    "\n",
    "                                                          'pred_out_mean': pred_out_mean,\n",
    "                                                          'pred_tot_std' : pred_tot_std,\n",
    "                                                          'pred_in_std'  : pred_in_std,\n",
    "                                                          'pred_out_std' : pred_out_std},\n",
    "                                                         ignore_index=True)\n",
    "        else: \n",
    "            print(\"Model not found\")            \n",
    "        #fi\n",
    "        print('============')\n",
    "    #endFor\n",
    "    \n",
    "    # save results\n",
    "    get_all_patients_errors.to_csv(results_dir+'errors.csv',index=False)\n",
    "    stats_EEm_results.to_csv(results_dir+'predStats.csv',index=False)\n",
    "\n",
    "    true = stats_EEm_results['true_tot_mean']\n",
    "    pred = stats_EEm_results['pred_tot_mean']\n",
    "    # std_true  = stats_EEm_results['true_tot_std']\n",
    "    # std_pred  = stats_EEm_results['pred_tot_std']\n",
    "    # scatter\n",
    "    z = np.polyfit(true, pred, 1)\n",
    "    p = np.poly1d(z)\n",
    "    x_max = int(np.max(true)+1)\n",
    "    y_max = int(np.max(pred)+1)\n",
    "    plt.figure(figsize=(15,8))\n",
    "    plt.xlim([1,x_max])\n",
    "    plt.ylim([1,y_max])\n",
    "    plt.scatter(true, pred, c ='blue', alpha=0.5)#, label='Indoors')\n",
    "    plt.plot(true,p(true),\"b\")     \n",
    "    # plt.legend(loc='upper right')\n",
    "    plt.title('True Vs Predicted Average EEm per participant')\n",
    "    plt.xlabel('True')\n",
    "    plt.ylabel('Predicted')\n",
    "    plt.show()\n",
    "    plt.savefig(results_dir+'all_scatter.pdf')  \n",
    "    plt.close\n",
    "    \n",
    "    print('######################################')\n",
    "    print('Rsquared Median: '+str(get_all_patients_errors.rsquared.median())+' /SD:'+ str(get_all_patients_errors.rsquared.std()))\n",
    "    print('Rsquared Mean: '+str(get_all_patients_errors.rsquared.mean())+' /rms Mean:'+ str(get_all_patients_errors.rms.mean()))\n",
    "    print('--------------------------------------')\n",
    "    print('inRsquared Median: '+str(get_all_patients_errors.inRsquared.median())+' /SD:'+ str(get_all_patients_errors.inRsquared.std()))\n",
    "    print('inRsquared Mean: '+str(get_all_patients_errors.inRsquared.mean())+' /inRms Mean:'+ str(get_all_patients_errors.inRms.mean()))\n",
    "    print('--------------------------------------')\n",
    "    print('outRsquared Median: '+str(get_all_patients_errors.outRsquared.median())+' /SD:'+ str(get_all_patients_errors.outRsquared.std()))\n",
    "    print('outRsquared Mean: '+str(get_all_patients_errors.outRsquared.mean())+' /outRms Mean:'+ str(get_all_patients_errors.outRms.mean()))\n",
    "    print('######################################')\n",
    "    \n",
    "    return get_all_patients_errors, stats_EEm_results, df_allPred, df_allPredin, df_allPredout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train a model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Seqs path : /preprocessedData/sequences/...seqs_1val_EEm_10ds_std_50/\n",
      "Model name: GRUx3_dx3_EEm_10ds_2mins_50epochs_512batch_1val_std_aw_withBMI\n"
     ]
    }
   ],
   "source": [
    "# # # # # # # # # # # # FIXED VARs # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # \n",
    "n_batch = 512\n",
    "epochs = 50\n",
    "EEm_rate = 10\n",
    "minutes = 2\n",
    "aggr = 'std'\n",
    "BMI = True\n",
    "device = 'aw'  # aw: ankle and wrist data\n",
    "               # ankle: only ankle data\n",
    "               # wrist: only wrist data\n",
    "\n",
    "model_function = 'GRUx3_dx3_EEm'\n",
    "seq_path = '/preprocessedData/sequences/...seqs_1val_EEm_10ds_std_50/'\n",
    "orig_seq_path = '/preprocessedData/sequences/...seqs_1val_EEm_10ds_std_50/' # test with orignal target data\n",
    "model_name = model_function+'_'+str(EEm_rate)+'ds_'+str(minutes)+'mins_'+str(epochs)+'epochs_'+str(n_batch)+'batch_1val_'+aggr+'_' + device\n",
    "\n",
    "# if you train with or without participants detail data\n",
    "if BMI==False:\n",
    "    model_name = model_name+'_noBMI'\n",
    "else:\n",
    "    model_name = model_name+'_withBMI'\n",
    "\n",
    "model_dir = 'models/' + model_name\n",
    "image_dir = 'images/' + model_name + '/Accur_Loss_figures/'\n",
    "predPlot_dir = 'images/' + model_name + '/predPlot/'\n",
    "\n",
    "print('Seqs path :', seq_path)\n",
    "print('Model name:', model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train model\n",
    "train_model(list_of_participants, orig_seq_path, seq_path, device, EE_modeling, image_dir, model_dir, predPlot_dir, BMI)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate a model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: models/GRUx3_dx3_EEm_10ds_2mins_50epochs_512batch_1val_std_aw_withBMI/\n",
      "Seqs: /preprocessedData/sequences/...seqs_1val_EEm_10ds_std_50/\n",
      "results_dir: images/GRUx3_dx3_EEm_10ds_2mins_50epochs_512batch_1val_std_aw_withBMI/predPlot/\n"
     ]
    }
   ],
   "source": [
    "# give participants to evaluate\n",
    "list_of_models = list(range(5, 36+1))\n",
    "# read EEm details\n",
    "# EEm_details = pd.read_csv('EEm_details_per_partic.csv')  \n",
    "\n",
    "# evaluate model with orignal target data\n",
    "target_seqs_dir = orig_seq_path\n",
    "\n",
    "trained_models_dir = model_dir+'/'\n",
    "\n",
    "results_dir = predPlot_dir\n",
    "\n",
    "print('Model:', trained_models_dir)\n",
    "print('Seqs:', target_seqs_dir)\n",
    "print('results_dir:', results_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "dire= list(glob.glob(trained_models_dir +'*.hdf5'))\n",
    "dire.sort()\n",
    "print('N=',len(dire))\n",
    "dire"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict\n",
    "get_all_patients_errorsf, stats_EEm_resultsf, df_allPredf, df_allPredinf, df_allPredoutf = predict_EE(list_of_models, \n",
    "                                                                                                 trained_models_dir,\n",
    "                                                                                                 target_seqs_dir,\n",
    "                                                                                                 EEm_details, \n",
    "                                                                                                 results_dir, \n",
    "                                                                                                 device)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
